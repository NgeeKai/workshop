{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrxubbputtga",
        "outputId": "dd0d095a-5191-41bc-de2f-5aefdcf64d5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am your chatbot Loki.\n",
            "You: hi\n",
            "Chatbot: Hello!\n",
            "You: bye\n",
            "Chatbot: Goodbye, see you again!\n"
          ]
        }
      ],
      "source": [
        "def simple_chatbot():\n",
        "    print(\"Hello! I am your chatbot Loki.\")\n",
        "\n",
        "   #############Please change the content below#############\n",
        "    responses = {\n",
        "        \"hi\": \"Hello!\",\n",
        "        \"hello\": \"Hi there!\",\n",
        "        \"hey\": \"Hey!\",\n",
        "        \"how are you\": \"I'm doing well, how about you?\",\n",
        "        \"what is your name\": \"I am Loki.\",\n",
        "        \"bye\": \"Goodbye! Have a great day!\"\n",
        "        #### add more items here.####\n",
        "    }\n",
        "    ########################################################\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").lower()\n",
        "        if user_input in [\"bye\", \"exit\", \"quit\"]:\n",
        "            print(\"Chatbot: Goodbye, see you again!\")\n",
        "            break\n",
        "\n",
        "        response = responses.get(user_input, \"I'm not sure how to respond.\")\n",
        "        print(\"Chatbot:\", response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    simple_chatbot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enhanced with Fazzy control**"
      ],
      "metadata": {
        "id": "O0oyGXGH49Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy[speedup]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE1HV4Eq4q1g",
        "outputId": "f05640b3-4ca0-48e0-b2e1-f5c4e78374f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.27.1 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
            "Successfully installed Levenshtein-0.27.1 fuzzywuzzy-0.18.0 python-levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz"
      ],
      "metadata": {
        "id": "k6QMoz9m4xV6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "def smart_chatbot():\n",
        "    print(\"Hello! I am your smart chatbot Loki.\")\n",
        "\n",
        "   #############Please change the content below#############\n",
        "    responses = {\n",
        "        \"hi\": \"Hello!\",\n",
        "        \"hello\": \"Hi there!\",\n",
        "        \"hey\": \"Hey!\",\n",
        "        \"how are you\": \"I'm doing well, how about you?\",\n",
        "        \"what is your name\": \"I am Loki.\",\n",
        "        \"bye\": \"Goodbye! Have a great day!\"\n",
        "        #### add more items here.####\n",
        "    }\n",
        "\n",
        "    FAZZY_THRESHOLD = 20    ### you may change the number 10-90\n",
        "    ###########################################################\n",
        "\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").lower()\n",
        "        if user_input in [\"bye\", \"exit\", \"quit\"]:\n",
        "            print(\"Chatbot: Goodbye!\")\n",
        "            break\n",
        "\n",
        "        # Fuzzy matching\n",
        "        best_match = None\n",
        "        best_score = 0\n",
        "\n",
        "        for key in responses:\n",
        "            score = fuzz.ratio(user_input, key)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = key\n",
        "\n",
        "        if best_score > FAZZY_THRESHOLD:  # Adjust threshold as needed\n",
        "            response = responses.get(best_match, \"I'm not sure how to respond to that.\")\n",
        "            print(\"Chatbot:\", response)\n",
        "        else:\n",
        "            print(\"Chatbot: I'm not sure how to respond to that.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    smart_chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pbfa3sB42VI",
        "outputId": "6741bba3-ddb7-42e3-dd18-eda88c56b41a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am your smart chatbot Loki.\n",
            "You: your name\n",
            "Chatbot: I am Loki.\n",
            "You: bye\n",
            "Chatbot: Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sentiment analysis**"
      ],
      "metadata": {
        "id": "cHmCLf0k7Awp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcixQ-4Xux4p",
        "outputId": "d62fe754-2938-4f7e-f697-011cd265e769"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.11/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.11/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######### You don't need to change any code #######\n",
        "from textblob import TextBlob\n",
        "\n",
        "def analyse_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return analysis.sentiment.polarity,analysis.sentiment.subjectivity\n",
        "\n",
        "\n",
        "your_text =input(\"Please type in your text: \")\n",
        "sentiment_score, sentiment_subjectivity = analyse_sentiment(your_text)\n",
        "print(f\"Sentiment Score (-1,1): {sentiment_score:.2f}\")\n",
        "print(f\"Sentiment subjectivity (0-1) 1 is very subjective: {sentiment_subjectivity:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpMEAML87AEZ",
        "outputId": "4c1cb628-2c2d-4697-fa0c-54831e2ee331"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please type in your text: good girl\n",
            "Sentiment Score (-1,1): 0.70\n",
            "Sentiment subjectivity (0-1) 1 is very subjective: 0.60\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}